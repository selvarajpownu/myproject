{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425bb713",
   "metadata": {},
   "source": [
    "# Video Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dabcf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vid=cv2.VideoCapture(0) # 0 is default value. used for webcam capture\n",
    "while vid.isOpened():\n",
    "    _,frame=vid.read()\n",
    "    frame=cv2.resize(frame,(640,640))\n",
    "    cv2.imshow(\"Camera Capture\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576fb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vid=cv2.VideoCapture('video.mp4')\n",
    "while vid.isOpened():\n",
    "    _,frame=vid.read()\n",
    "    frame=cv2.resize(frame,(640,640),interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(\"Camera Capture\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d021122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "images=[img for img in os.listdir(os.getcwd()) if img.endswith(\".jpg\")]\n",
    "\n",
    "vid=cv2.VideoWriter(\"Video1.avi\",0,1,(480,480)) # filename, codec[0 is default], fps, frame size\n",
    "for f in images:\n",
    "    vid.write(cv2.resize(cv2.imread(os.path.join(os.getcwd(),f)),(480,480)))\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a2ec0",
   "metadata": {},
   "source": [
    "### Practice\n",
    "1. Load image\n",
    "2. Apply Filter\n",
    "3. Convert Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59961cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "images = [img for img in os.listdir(os.getcwd()) if img.endswith(\".jpg\")]\n",
    "\n",
    "filterimg = []\n",
    "for i in images:\n",
    "    img = cv2.imread(os.path.join(os.getcwd(), i))\n",
    "    # Applying Filter\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    filterimg.append(hsv_img)\n",
    "\n",
    "vid = cv2.VideoWriter(\"Video1.avi\", 0, 1, (480, 480))\n",
    "\n",
    "for f in filterimg:\n",
    "   \n",
    "    resized_img = cv2.resize(f, (480, 480))\n",
    "    vid.write(resized_img)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819118d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a5c6e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd8f9e",
   "metadata": {},
   "source": [
    "### Codecs\n",
    "  1. Codecs, short for \"coder-decoder,\" are software or hardware components that encode (compress) and decode (decompress) digital data, such as audio and video. They play a crucial role in various multimedia applications, including streaming, video conferencing, and file compression. Codecs are essential for efficiently storing and transmitting multimedia content by reducing the size of the data without significantly compromising its quality.\n",
    "\n",
    "  2. Video Codecs: Video codecs are designed for compressing and decompressing video data. \n",
    "        1. H.264 (Advanced Video Coding): \n",
    "        Widely used for video compression, including in Blu-ray discs, streaming services, and video conferencing.\n",
    "        2. H.265 (High Efficiency Video Coding or HEVC): \n",
    "        An improvement over H.264, providing better compression while maintaining similar video quality. Commonly used in 4K video streaming.\n",
    "        3. VP9: Developed by Google, VP9 is an open-source video codec designed to provide efficient compression for web video content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab065e",
   "metadata": {},
   "source": [
    "### Video compression\n",
    "Video compression refers to the process of reducing the file size of a video by encoding or converting it in such a way that it requires less storage space than the original file without significantly sacrificing quality.\n",
    "### Encoding\n",
    "encoding/encryption is used to protect sensitive data from unauthorized access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b13e9",
   "metadata": {},
   "source": [
    "### Bitrate\n",
    "Bitrate in the context of video refers to the amount of data processed or transmitted per unit of time in a video file. It is commonly expressed in bits per second (bps), kilobits per second (kbps), or megabits per second (Mbps)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03384a",
   "metadata": {},
   "source": [
    "### Frame:\n",
    "\n",
    "1. A frame is a single still image in a sequence of images that, when played in rapid succession, creates the illusion of motion. In the context of video, each frame represents a single picture in the entire video sequence.\n",
    "2. The quality of an individual frame contributes to the overall visual quality of the video. Higher resolution frames generally result in clearer and more detailed videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6491b98e",
   "metadata": {},
   "source": [
    "### Frames Per Second (FPS):\n",
    "\n",
    "1. FPS is a measure of how many individual frames are displayed in one second of video playback. It represents the frame rate or the speed at which the video appears to move.\n",
    "2. Higher FPS values often result in smoother motion in videos, especially for fast-paced or high-action scenes.\n",
    "3. The best frame rate for video:\n",
    "    1. less than 16 FPS: recreating the look of the silent era movies\n",
    "    2. 24 FPS: the most cinematic look\n",
    "    3. 30 FPS: used by TV and excellent for live sports\n",
    "    4. 60 FPS: walking, candles being blown out, etc.\n",
    "    5. 120 FPS: people running, nature videography, etc.\n",
    "    6. 240 FPS: balloons exploding, water splashes, etc.\n",
    "    7. 480 FPS: skateboard tricks, skiing, surfing, etc.\n",
    "    8. 960+ FPS: Hyper-slow motion. Think about the explosion sequence from The Hurt Locker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14d07da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames saved to frames\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "video_path = 'myVideo.avi'\n",
    "output_folder = 'frames'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened() and cap.grab():\n",
    "    _, frame = cap.retrieve()\n",
    "    frame_count += 1\n",
    "    cv2.imwrite(f\"{output_folder}/frame_{frame_count:04d}.jpg\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Frames saved to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adbe4cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<------Default Flags Values ------->\n",
      "\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print('<------Default Flags Values ------->\\n')\n",
    "print(cv2.CAP_PROP_FPS)\n",
    "print(cv2.CAP_PROP_FPS)\n",
    "print(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "print(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "print(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print(cv2.CAP_PROP_FORMAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ca21d",
   "metadata": {},
   "source": [
    "### Getting FPS, Frame count, height, width of an video using flags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e38b98c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<------Flags Values for video------->\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n",
      "FPS : 1.0\n",
      "FRAME COUNT : 16.0\n",
      "HEIGHT : 480.0\n",
      "WIDTH : 480.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2,os\n",
    "cap=cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "print('<------Flags Values for video------->\\n')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    print('FPS :',cap.get(cv2.CAP_PROP_FPS))\n",
    "    print('FRAME COUNT :',cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('HEIGHT :',cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print('WIDTH :',cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    print()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e309be",
   "metadata": {},
   "source": [
    "### Count frames in an Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "514872eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Frames in a Video 17\n"
     ]
    }
   ],
   "source": [
    "import cv2,os\n",
    "cap=cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read() # ret is boolean value, TRUE if frame read is successful\n",
    "    cap.get(cv2.CAP_PROP_FPS)\n",
    "    count += 1\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "print('Total Frames in a Video', count)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "cap=cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "print('<------Flags Values for video------->\\n')\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    print('FPS :',cap.get(cv2.CAP_PROP_FPS))\n",
    "    print('FRAME COUNT :',cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print('HEIGHT :',cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print('WIDTH :',cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    \n",
    "    print()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63c9edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "480.0\n",
      "480.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "print(vid.get(cv2.CAP_PROP_FPS))\n",
    "print(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(vid.get(cv2.CAP_PROP_AUDIO_TOTAL_CHANNELS))\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    if count >=10:\n",
    "        break\n",
    "    cv2.imshow(f\"Frame {count}\",frame)\n",
    "    cv2.imwrite(f\"frames/pic{count}.jpg\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    count += 1\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc4fb5",
   "metadata": {},
   "source": [
    "### Blur frames of a video for few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e4f9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture('video.mp4')\n",
    "count = 0\n",
    "frames = []\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    kernel_size = (25, 25)\n",
    "    if not ret:break\n",
    "    if count <= 4:\n",
    "        blur_frame = cv2.GaussianBlur(frame, kernel_size,0)\n",
    "        frames.append(blur_frame)\n",
    "    else:\n",
    "        frames.append(frame)\n",
    "    count += 1\n",
    "\n",
    "vid.release()\n",
    "output_vid = cv2.VideoWriter(\"video.mp4\", 0, 1, (480, 480))\n",
    "\n",
    "for f in frames:\n",
    "    output_vid.write(f)\n",
    "\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcc89a",
   "metadata": {},
   "source": [
    "### Blur frames of a video for few seconds and save it in same file[we need to read video and then release video before Blur/editing the frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6ffb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "frames = []\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    kernel_size = (25, 25)\n",
    "    if not ret:break\n",
    "    if count <= 4:\n",
    "        blur_frame = cv2.GaussianBlur(frame, kernel_size,0)\n",
    "        frames.append(blur_frame)\n",
    "    else:\n",
    "        frames.append(frame)\n",
    "    count += 1\n",
    "\n",
    "vid.release()\n",
    "output_vid = cv2.VideoWriter(\"myVideo.avi\", 0, 1, (480, 480))\n",
    "\n",
    "for f in frames:\n",
    "    output_vid.write(f)\n",
    "\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ab1f5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "start = 0 \n",
    "end = fps*7\n",
    "frames =[]\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    kernel_size = (25, 25)\n",
    "    if not ret:break\n",
    "    if start <= count <= end:\n",
    "        blur_frame = cv2.GaussianBlur(frame, kernel_size,0)\n",
    "        frames.append(blur_frame)\n",
    "    else:\n",
    "        frames.append(frame)\n",
    "    count += 1\n",
    "\n",
    "vid.release()\n",
    "output_vid = cv2.VideoWriter(\"outputVideo.avi\", 0, 1, (480, 480))\n",
    "\n",
    "for f in frames:\n",
    "    output_vid.write(f)\n",
    "\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21450a54",
   "metadata": {},
   "source": [
    "### Write a program read video and get start and end value from user to trim the video and save it to the system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa8dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter start value4\n",
      "Enter end value7\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "start = int(input('Enter start value')) \n",
    "end = int(input('Enter end value'))\n",
    "frames1 =[]\n",
    "frames2 = []\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    if start <= count <= end:\n",
    "        frames1.append(frame)\n",
    "    else:\n",
    "        frames2.append(frame)\n",
    "    count += 1\n",
    "\n",
    "vid.release()\n",
    "\n",
    "output_vid = cv2.VideoWriter(\"trimmedVideo1.avi\", 0, 1, (480, 480))\n",
    "for f in frames1:\n",
    "    output_vid.write(f)\n",
    "\n",
    "output_vid = cv2.VideoWriter(\"trimmedVideo2.avi\", 0, 1, (480, 480))    \n",
    "for f in frames2:\n",
    "    output_vid.write(f)\n",
    "\n",
    "\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31933575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter start value :5\n",
      "Enter end value :8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "count = 0\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "start = int(input('Enter start value :')) \n",
    "end = int(input('Enter end value :'))\n",
    "frames1 =[]\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    if start <= count <= end:\n",
    "        frames1.append(frame)\n",
    "    count += 1\n",
    "\n",
    "vid.release()\n",
    "\n",
    "output_vid = cv2.VideoWriter(\"trimmedVideo.avi\", 0, fps, (480, 480))\n",
    "\n",
    "for f in frames1:\n",
    "    output_vid.write(f)\n",
    "    \n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093c043",
   "metadata": {},
   "source": [
    "### Merge two Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5a23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "vid1 = cv2.VideoCapture('trimmedVideo.avi')\n",
    "\n",
    "merge_frames = []\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    merge_frames.append(frame)\n",
    "\n",
    "while vid1.isOpened():\n",
    "    ret, frame = vid1.read()\n",
    "    if not ret:break\n",
    "    merge_frames.append(frame)\n",
    "    \n",
    "vid.release()\n",
    "vid1.release()\n",
    "\n",
    "merge_vid = cv2.VideoWriter(\"mergededVideo.avi\", 0, 1, (480, 480))\n",
    "\n",
    "for f in merge_frames:\n",
    "    merge_vid.write(f)\n",
    "    \n",
    "merge_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18011f8c",
   "metadata": {},
   "source": [
    "### Canny Edge on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5deee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "frames = []\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    canny_edges = cv2.Canny(frame, 50, 150)\n",
    "    frames.append(canny_edges)\n",
    "\n",
    "vid.release()\n",
    "output_vid = cv2.VideoWriter('cannyVideo.avi', 0, 1, (480, 480))\n",
    "\n",
    "for f in frames:\n",
    "    # Convert grayscale frame to BGR before writing\n",
    "    bgr_frame = cv2.cvtColor(f, cv2.COLOR_GRAY2BGR)\n",
    "    output_vid.write(bgr_frame)\n",
    "\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3399175",
   "metadata": {},
   "source": [
    "### Histograms On video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9a633e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture('trimmedVideo.avi')\n",
    "\n",
    "output_vid = cv2.VideoWriter('histogram.avi', 0, 1, (256, 256))\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # histogram\n",
    "    histogram = cv2.calcHist([frame], [0], None, [256], [0, 180])\n",
    "    hist_image = np.zeros((256, 256), dtype=np.uint8)\n",
    "    cv2.normalize(histogram, histogram, 0, hist_image.shape[0], cv2.NORM_MINMAX)\n",
    "\n",
    "    for i in range(256):\n",
    "        cv2.line(hist_image, (i, hist_image.shape[0]), (i, hist_image.shape[0] - int(histogram[i])), 255)\n",
    "\n",
    "    bgr_frame = cv2.cvtColor(hist_image, cv2.COLOR_GRAY2BGR)\n",
    "    output_vid.write(bgr_frame)\n",
    "\n",
    "vid.release()\n",
    "output_vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54227b9e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf1fa9",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92444094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "image_path = 'group.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face.detectMultiScale(gray_img, scaleFactor=1.2, minNeighbors=8) # scaleFactor is zoom-[>1], minNeighbours is \n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "cv2.imshow('Detected Faces', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4328662",
   "metadata": {},
   "source": [
    "# Face Detection in videos and save face detected image file in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dae5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture('faceVideo1.avi')\n",
    "count = 0\n",
    "\n",
    "face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face.detectMultiScale(gray_img, scaleFactor=1.2, minNeighbors=8)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.imwrite(f'img{count}.png', frame)\n",
    "    count += 1\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f775c0",
   "metadata": {},
   "source": [
    "## Face Detection in videos and save face detected video file in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec82b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture('faceVideo1.avi')\n",
    "output_vid = cv2.VideoWriter('detectedface.avi', 0, 1, (480,480))\n",
    "\n",
    "face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face.detectMultiScale(gray_img, scaleFactor=1.2, minNeighbors=8)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        output_vid.write(frame)\n",
    "\n",
    "output_vid.release()\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e661e6e",
   "metadata": {},
   "source": [
    "### haarcascade datasets\n",
    "    haarcascade_eye_tree_eyeglasses.xml\n",
    "    haarcascade_eye.xml\n",
    "    haarcascade_frontalcatface_extended.xml\n",
    "    haarcascade_frontalcatface.xml\n",
    "    haarcascade_frontalface_alt2.xml\n",
    "    haarcascade_frontalface_alt_tree.xml\n",
    "    haarcascade_frontalface_alt.xml\n",
    "    haarcascade_frontalface_default.xml\n",
    "    haarcascade_fullbody.xml\n",
    "    haarcascade_lefteye_2splits.xml\n",
    "    haarcascade_license_plate_rus_16stages.xml\n",
    "    haarcascade_lowerbody.xml\n",
    "    haarcascade_profileface.xml\n",
    "    haarcascade_righteye_2splits.xml\n",
    "    haarcascade_russian_plate_number.xml\n",
    "    haarcascade_smile.xml\n",
    "    haarcascade_upperbody.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2afc172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_russian_plate_number.xml')\n",
    "image_path = 'numberplate.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face.detectMultiScale(gray_img, scaleFactor=1.2, minNeighbors=8) # scaleFactor is zoom-[>1], minNeighbours is \n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "cv2.imshow('Detected plate', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0a6b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "mainImg = cv2.imread('person.jpg')\n",
    "\n",
    "output_vid = cv2.VideoWriter('TemplateMatching.avi', 0, 1, (480,480))\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "\n",
    "    result = cv2.matchTemplate(mainImg, frame, cv2.TM_CCOEFF_NORMED)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    cv2.rectangle(mainImg, max_loc, (max_loc[0] + w, max_loc[1] + h), (0, 255, 0), 2)\n",
    "    output_vid.write(mainImg)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d499e195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(x)  for x in range(0,11,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96300eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{print(x) for x in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a776e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'type'>\n"
     ]
    }
   ],
   "source": [
    "class abc:pass\n",
    "class a():pass\n",
    "A=abc()\n",
    "print(type(abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba11a92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class '__main__.animal'>, <class '__main__.sound'>, <class '__main__.walk'>)\n"
     ]
    }
   ],
   "source": [
    "class animal:pass\n",
    "class sound:pass\n",
    "class walk:pass\n",
    "class dog(animal,sound,walk):pass\n",
    "print(dog.__bases__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560f09e1",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec7d26f4",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "#lk=dict()\n",
    "mask=np.random.randint(0,255,(100,4))\n",
    "ret1, frame1 = vid.read()\n",
    "gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4affd3",
   "metadata": {},
   "source": [
    "# Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90906935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "ret1, frame1 = vid.read()\n",
    "gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "print(points1)\n",
    "mask2=np.zeros_like(frame1)\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "    newpts=points1[status==1]\n",
    "    oldpts=points1[status==1]\n",
    "    for x,(new,old) in enumerate(zip(newpts,oldpts)):\n",
    "        a,b=new.ravel()#2D->1D Array\n",
    "        c,d=old.ravel()\n",
    "        mask2=cv2.line(mask2,(int(a),int(b)),(int(c),int(d)),(0,255,255),4)\n",
    "        frame=cv2.circle(frame,(int(a),int(b)),5,(0,255,0),-1)\n",
    "    print(frame.shape)\n",
    "    print(mask2.shape)\n",
    "    image=cv2.add(frame,mask2)\n",
    "    cv2.imshow(\"Frame\",image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448787bc",
   "metadata": {},
   "source": [
    "#### Enter Frame number want to track [ method 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa08ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the starting frame: 4\n",
      "[[[135. 210.]]\n",
      "\n",
      " [[205. 161.]]\n",
      "\n",
      " [[ 90. 155.]]\n",
      "\n",
      " [[449. 221.]]]\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "frameS=int(input(\"enter the starting frame: \"))\n",
    "vid.set(cv2.CAP_PROP_POS_FRAMES, frameS)\n",
    "ret1, frame1 = vid.read()\n",
    "gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "print(points1)\n",
    "mask2=np.zeros_like(frame1)\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "    newpts=points1[status==1]\n",
    "    oldpts=points1[status==1]\n",
    "    for x,(new,old) in enumerate(zip(newpts,oldpts)):\n",
    "        a,b=new.ravel()#2D->1D Array\n",
    "        c,d=old.ravel()\n",
    "        mask2=cv2.line(mask2,(int(a),int(b)),(int(c),int(d)),(0,255,255),4)\n",
    "        frame=cv2.circle(frame,(int(a),int(b)),5,(0,255,0),-1)\n",
    "    print(frame.shape)\n",
    "    print(mask2.shape)\n",
    "    image=cv2.add(frame,mask2)\n",
    "    cv2.imshow(\"Frame\",image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778a60a",
   "metadata": {},
   "source": [
    "#### method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51148021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter frame number:\t6\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('video')\n",
    "#lk=dict()\n",
    "frame_count=0\n",
    "frame_no=int(input(\"enter frame number:\\t\"))\n",
    "while vid.isOpened():\n",
    "    ret1, frame1 = vid.read()\n",
    "    if frame_no==frame_count:\n",
    "        gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "        points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "        mask2=np.zeros_like(frame1)\n",
    "        break\n",
    "    frame_count+=1\n",
    "vid.release()\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "    newpts=points1[status==1]\n",
    "    oldpts=points1[status==1]\n",
    "    for x,(new,old) in enumerate(zip(newpts,oldpts)):\n",
    "        a,b=new.ravel()#2D->1D Array\n",
    "        c,d=old.ravel()\n",
    "        mask2=cv2.line(mask2,(int(a),int(b)),(int(c),int(d)),(0,255,255),4)\n",
    "        frame=cv2.circle(frame,(int(a),int(b)),5,(0,255,0),-1)\n",
    "    print(frame.shape)\n",
    "    print(mask2.shape)\n",
    "    image=cv2.add(frame,mask2)\n",
    "    cv2.imshow(\"Frame\",image)\n",
    "    cv2.waitKey(0)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf6eef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n",
      "(480, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "#lk=dict()\n",
    "ret1, frame1 = vid.read()\n",
    "gray1=cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "points1=cv2.goodFeaturesToTrack(gray1,mask=None,maxCorners=100,qualityLevel=0.5,minDistance=10,blockSize=10)\n",
    "#print(points1)\n",
    "mask2=np.zeros_like(frame1)\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    points2,status,err=cv2.calcOpticalFlowPyrLK(gray1,gray,points1,None,winSize=(15,15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "    newpts=points1[status==1]\n",
    "    oldpts=points1[status==1]\n",
    "    for x,(new,old) in enumerate(zip(newpts,oldpts)):\n",
    "        a,b=new.ravel()#2D->1D Array\n",
    "        c,d=old.ravel()\n",
    "        mask2=cv2.line(mask2,(int(a),int(b)),(int(c),int(d)),(0,255,255),4)\n",
    "        frame=cv2.circle(frame,(int(a),int(b)),5,(0,255,0),-1)\n",
    "    print(frame.shape)\n",
    "    print(mask2.shape)\n",
    "    image=cv2.add(frame,mask2)\n",
    "    cv2.imshow(\"Frame\",image)\n",
    "    cv2.waitKey(0)\n",
    "    gray1=gray.copy()\n",
    "    points1=newpts.reshape(-1,1,2)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed3079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('myVideo.avi')\n",
    "x,y,h,w=200,200,100,100\n",
    "roi=(x,y,w,h)\n",
    "criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "ret1, frame1 = vid.read()\n",
    "frame_roi=frame1[y:y+h,x:x+w]\n",
    "hsv=cv2.cvtColor(frame_roi,cv2.COLOR_BGR2HSV)\n",
    "hist=cv2.calcHist([hsv],[0],None,[180],[0,180])\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    hsv_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    dst=cv2.calcBackProject([hsv_frame],[0],hist,[0,180],1)\n",
    "    outp,rei=cv2.meanShift(dst,roi,criteria)\n",
    "    x,y,w,h=roi\n",
    "    result=cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    cv2.imshow(\"Meanshift\",result)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980fd27d",
   "metadata": {},
   "source": [
    "## MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "708b40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('Video1.avi')\n",
    "x,y,h,w=200,200,100,100\n",
    "roi=(x,y,w,h)\n",
    "criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "ret1, frame1 = vid.read()\n",
    "frame_roi=frame1[y:y+h,x:x+w]\n",
    "hsv=cv2.cvtColor(frame_roi,cv2.COLOR_BGR2HSV)\n",
    "hist=cv2.calcHist([hsv],[0],None,[180],[0,180])\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    hsv_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    dst=cv2.calcBackProject([hsv_frame],[0],hist,[0,180],1)\n",
    "    outp,rei=cv2.meanShift(dst,roi,criteria)\n",
    "    x,y,w,h=roi\n",
    "    result=cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    cv2.imshow(\"Meanshift\",result)\n",
    "    cv2.waitKey(0)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3bfd6",
   "metadata": {},
   "source": [
    "## CamShift or Adaptive MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea8136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid.release()\n",
    "vid=cv2.VideoCapture('Video1.avi')\n",
    "x,y,h,w=200,200,100,100\n",
    "roi=(x,y,w,h)\n",
    "criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,1)\n",
    "ret1, frame1 = vid.read()\n",
    "frame_roi=frame1[y:y+h,x:x+w]\n",
    "hsv=cv2.cvtColor(frame_roi,cv2.COLOR_BGR2HSV)\n",
    "hist=cv2.calcHist([hsv],[0],None,[180],[0,180])\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    hsv_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    dst=cv2.calcBackProject([hsv_frame],[0],hist,[0,180],1)\n",
    "    outp,rei=cv2.CamShift(dst,roi,criteria)\n",
    "    points=cv2.boxPoints(outp).astype(int)\n",
    "    result=cv2.polylines(frame,[points],True,(255,0,0),2)\n",
    "    cv2.imshow(\"Camshift\",result)\n",
    "    cv2.waitKey(0)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59931424",
   "metadata": {},
   "source": [
    "## Background Subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027da3f0",
   "metadata": {},
   "source": [
    "### Background Subtractor MOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b037a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('carvideo.mp4')\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "count=0\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', fg_mask)\n",
    "    if count > 20:\n",
    "        break\n",
    "    cv2.waitKey(0)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55f353",
   "metadata": {},
   "source": [
    "### Background Subtractor KNN - More Accurate and Sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3385b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('carvideo.mp4')\n",
    "\n",
    "bg_subtractor = cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=20, detectShadows=False)\n",
    "count=0\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    count+=1\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "    cv2.imshow('Original Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', fg_mask)\n",
    "    if count > 50:\n",
    "        break\n",
    "    cv2.waitKey(0)\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152447fd",
   "metadata": {},
   "source": [
    "### Appllying SIFT and ORB on a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5212b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture('myVideo.avi')\n",
    "height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# storing video file in specified path\n",
    "output_vid = cv2.VideoWriter(os.path.join(r'C:/Users/2001s/Desktop/video', 'sift.avi'), 0, 1, (height,width))\n",
    "output_orb = cv2.VideoWriter(os.path.join(r'C:/Users/2001s/Desktop/video', 'orb.avi'), 0, 1, (height,width))\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "orb = cv2.ORB_create()\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    # Sift\n",
    "    keypoints, descriptors = sift.detectAndCompute(frame, None)\n",
    "    sift_img = cv2.drawKeypoints(frame, keypoints, None)\n",
    "    output_vid.write(sift_img)\n",
    "    #ORB\n",
    "    keypoints, descriptors = orb.detectAndCompute(frame, None)\n",
    "    orb_img = cv2.drawKeypoints(frame, keypoints, None)\n",
    "    output_orb.write(orb_img)\n",
    "\n",
    "vid.release()\n",
    "output_vid.release()\n",
    "output_orb.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be037109",
   "metadata": {},
   "source": [
    "## Practice Exercise\n",
    "1. Load Video\n",
    "2. Apply GraphCut\n",
    "3. Count faces in frame\n",
    "4. Save in specified folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b53d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces in frame 0: 0\n",
      "faces in frame 1: 3\n",
      "faces in frame 2: 3\n",
      "faces in frame 3: 1\n",
      "faces in frame 4: 1\n",
      "faces in frame 5: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture('Video1.avi')\n",
    "count = 0\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while vid.isOpened():\n",
    "    ret, frame = vid.read()\n",
    "    if not ret:break\n",
    "    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.2, minNeighbors=8)\n",
    "\n",
    "    print(f'faces in frame {count}:',len(faces))\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        rect = (x, y, w, h)\n",
    "        #GrabCut\n",
    "        bgd_model = np.zeros((1, 65), np.float64)\n",
    "        fgd_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "        grabcut_mask = np.zeros(frame.shape[:2], np.uint8)\n",
    "        cv2.grabCut(frame, grabcut_mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
    "        mask2 = np.where((grabcut_mask == 2) | (grabcut_mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "        result = frame * mask2[:, :, np.newaxis]\n",
    "        cv2.imwrite(f'grabcutFrame/img{count}{i}.png', result)\n",
    "    count +=1\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture('VID-20211121-hri.mp4')\n",
    "print('abc')\n",
    "inp=int(input(\"Enter the Time where you want to start\"))\n",
    "fps=vid.get(cv2.CAP_PROP_FPS)\n",
    "count=0\n",
    "while (vid.isOpened()):\n",
    "    _,frame=vid.read()\n",
    "    count+=1\n",
    "    if count >= int(fps*float(inp)):\n",
    "        frame=cv2.resize(frame,(640,640),interpolation=cv2.INTER_CUBIC)\n",
    "        cv2.imshow(f\"Frames From {inp} Seconds-{count}\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ca039",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47d3c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "3/3 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "#cv2.imshow('s',cv2.imread('group.jpg',cv2.IMREAD_GRAYSCALE))\n",
    "img = cv2.imread('group.jpg',cv2.COLOR_BGR2GRAY)\n",
    "faces = detector.detect_faces(img)\n",
    "for face in faces:\n",
    "    x, y, width, height = face['box']\n",
    "    cv2.rectangle(img, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "cv2.imshow('Face Detection', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11441929",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m      7\u001b[0m gray_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m----> 8\u001b[0m faces \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mdetect_faces(gray_img) \u001b[38;5;66;03m# scaleFactor is zoom-[>1], minNeighbours is \u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[0;32m     10\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(img, (x, y), (x\u001b[38;5;241m+\u001b[39mw, y\u001b[38;5;241m+\u001b[39mh), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mtcnn\\mtcnn.py:287\u001b[0m, in \u001b[0;36mMTCNN.detect_faces\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidImage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not valid.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 287\u001b[0m height, width, _ \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    288\u001b[0m stage_status \u001b[38;5;241m=\u001b[39m StageStatus(width\u001b[38;5;241m=\u001b[39mwidth, height\u001b[38;5;241m=\u001b[39mheight)\n\u001b[0;32m    290\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_face_size\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "image_path = 'group.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = detector.detect_faces(gray_img) # scaleFactor is zoom-[>1], minNeighbours is \n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "cv2.imshow('Detected Faces', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b86f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "3/3 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN  # Make sure to import MTCNN from the correct module\n",
    "\n",
    "# Load the pre-trained MTCNN model\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load the image\n",
    "image_path = 'group.jpg'\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces using MTCNN\n",
    "faces = detector.detect_faces(img)\n",
    "\n",
    "# Draw rectangles around the detected faces\n",
    "for face in faces:\n",
    "    x, y, w, h = face['box']\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "# Display the image with detected faces\n",
    "cv2.imshow('Detected Faces', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977337e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
